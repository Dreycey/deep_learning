{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks (RNNs)\n",
    "\n",
    "This notebook contains examples of using RNNs for classification and regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_datasets, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, Input, Model\n",
    "\n",
    "# Keras imports\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, SimpleRNN, GRU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# word2vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# versions of libraries - noticed problems with Text vecotrization in lower versions\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset\n",
    "\n",
    "Here I am using a poem sentiment dataset under the category of sentiment-classification on huggingface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset poem_sentiment (/Users/dreyceyalbin/.cache/huggingface/datasets/poem_sentiment/default/1.0.0/4e44428256d42cdde0be6b3db1baa587195e91847adabf976e4f9454f6a82099)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5730de7b3afe4b88bc28cf0216043621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load dataset (X-tweets; Y-emotion)\n",
    "\n",
    "#####\n",
    "# DATA - https://huggingface.co/datasets/poem_sentiment\n",
    "#####\n",
    "dataset = load_dataset(\"poem_sentiment\")\n",
    "\n",
    "#dataset = load_dataset(\"emotion\")\n",
    "\n",
    "# load different datasets\n",
    "train = dataset['train']\n",
    "test = dataset['test']\n",
    "val = dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of 0 label in data set is 155\n",
      "count of 1 label in data set is 133\n",
      "count of 2 label in data set is 555\n",
      "count of 3 label in data set is 49\n",
      "count of 0 label in data set is 155\n",
      "count of 1 label in data set is 133\n",
      "count of 2 label in data set is 156\n",
      "count of 3 label in data set is 49\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Data preperation\n",
    "###\n",
    "index2meaning = {0 : \"negative\",\n",
    "                 1 : \"positive\",\n",
    "                 2 : \"no_impact\",\n",
    "                 3 : \"mixed\"}\n",
    "## training data\n",
    "train_samples = [x['verse_text'] for x in train]\n",
    "train_labels = np.array([x['label'] for x in train]) # already numerical\n",
    "## validation data\n",
    "val_samples = [x['verse_text'] for x in val]\n",
    "val_labels = np.array([x['label'] for x in val]) # already numerical\n",
    "## test data\n",
    "test_samples = [x['verse_text'] for x in test]\n",
    "test_labels = np.array([x['label'] for x in test]) # already numerical\n",
    "\n",
    "# obtain class balance data\n",
    "print(f\"count of 0 label in data set is {sum(train_labels == 0)}\")\n",
    "print(f\"count of 1 label in data set is {sum(train_labels == 1)}\")\n",
    "print(f\"count of 2 label in data set is {sum(train_labels == 2)}\")\n",
    "print(f\"count of 3 label in data set is {sum(train_labels == 3)}\")\n",
    "\n",
    "\n",
    "# clean dataset\n",
    "train_samples_cleaned = []\n",
    "train_labels_cleaned = []\n",
    "count_dict = {0 : 0, 1:0, 2:0, 3:0}\n",
    "for index, value in enumerate(train_labels):\n",
    "    value = int(value)\n",
    "    if count_dict[value] <= 155:\n",
    "        train_samples_cleaned.append(train_samples[index])\n",
    "        train_labels_cleaned.append(train_labels[index])\n",
    "    count_dict[value] += 1\n",
    "    \n",
    "# clean original values\n",
    "train_samples = np.array(train_samples_cleaned.copy())\n",
    "train_labels = np.array(train_labels_cleaned.copy())\n",
    "\n",
    "# obtain class balance data\n",
    "print(f\"count of 0 label in data set is {sum(train_labels == 0)}\")\n",
    "print(f\"count of 1 label in data set is {sum(train_labels == 1)}\")\n",
    "print(f\"count of 2 label in data set is {sum(train_labels == 2)}\")\n",
    "print(f\"count of 3 label in data set is {sum(train_labels == 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorizer to tokenize sentences.\n",
    "\n",
    "# parameters\n",
    "EMBEDDED_VEC_LENGTH = 100\n",
    "MAX_VOCABULARY = 10000\n",
    "# vectorize\n",
    "vectorizer = TextVectorization(max_tokens=MAX_VOCABULARY, \n",
    "                               output_sequence_length=EMBEDDED_VEC_LENGTH, \n",
    "                               output_mode='int')\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128) ## Read batches of 128 samples\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2323\n"
     ]
    }
   ],
   "source": [
    "## Print out top five words in the vocab\n",
    "print(len(vectorizer.get_vocabulary())) ## We set max_tokens=10000\n",
    "vectorizer.get_vocabulary()[:5]\n",
    "## Text an example of what a string looks like after vectorization\n",
    "output = vectorizer([[\"I feel good today again\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a map to get the unique list of the vocabulary\n",
    "#####\n",
    "# COPIED FROM LECTURE\n",
    "####\n",
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  10 1323  628 ...    0    0    0]\n",
      " [  13 1787   27 ...    0    0    0]\n",
      " [   3    9   15 ...    0    0    0]\n",
      " ...\n",
      " [ 180  762 1523 ...    0    0    0]\n",
      " [  53 1737   19 ...    0    0    0]\n",
      " [   7    2  188 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "## Vectorize our data (Convert the string data to integer data)\n",
    "\n",
    "# Feature vectors\n",
    "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
    "x_test = vectorizer(np.array([[s] for s in test_samples])).numpy()\n",
    "\n",
    "print(x_train)\n",
    "# Labels (not categorical!)\n",
    "CATEGORICAL = False\n",
    "if CATEGORICAL:\n",
    "    y_train = to_categorical(train_labels)\n",
    "    y_val = to_categorical(val_labels)\n",
    "    y_test = to_categorical(test_labels)\n",
    "else: \n",
    "    y_train = np.array(train_labels)\n",
    "    y_val = np.array(val_labels)\n",
    "    y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure data has correct shape\n",
    "# reshape into [samples, timesteps, features]\n",
    "\n",
    "# x_train_no_emb = np.reshape(x_train, (len(x_train), EMBEDDED_VEC_LENGTH, 1)) / float(len(voc))\n",
    "# x_val_no_emb = np.reshape(x_val, (len(x_val), EMBEDDED_VEC_LENGTH, 1)) / float(len(voc))\n",
    "# x_test_no_emb = np.reshape(x_test, (len(x_test), EMBEDDED_VEC_LENGTH, 1)) / float(len(voc))\n",
    "\n",
    "\n",
    "x_train_no_emb = np.reshape(x_train, (len(x_train), EMBEDDED_VEC_LENGTH, 1))\n",
    "x_val_no_emb = np.reshape(x_val, (len(x_val), EMBEDDED_VEC_LENGTH, 1)) \n",
    "x_test_no_emb = np.reshape(x_test, (len(x_test), EMBEDDED_VEC_LENGTH, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  10],\n",
       "        [1323],\n",
       "        [ 628],\n",
       "        ...,\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0]],\n",
       "\n",
       "       [[  13],\n",
       "        [1787],\n",
       "        [  27],\n",
       "        ...,\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0]],\n",
       "\n",
       "       [[   3],\n",
       "        [   9],\n",
       "        [  15],\n",
       "        ...,\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 180],\n",
       "        [ 762],\n",
       "        [1523],\n",
       "        ...,\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0]],\n",
       "\n",
       "       [[  53],\n",
       "        [1737],\n",
       "        [  19],\n",
       "        ...,\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0]],\n",
       "\n",
       "       [[   7],\n",
       "        [   2],\n",
       "        [ 188],\n",
       "        ...,\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_no_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Testing into short, medium, and long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short count = 40\n",
      "medium count = 24\n",
      "long count = 40\n",
      "[1, 2, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 0, 2, 1, 2, 0, 0, 0, 2, 1, 1, 2, 2, 2, 0, 2, 1, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYpElEQVR4nO3de7QlZX3m8e9j0+FuADlAQzd9DMMQCQkNHhADKhdJEAkXl2bJANOjSDuzgOAEE0AdLpIoWQqoywxJK5eO3EJALiGY0GmlCRkDHu4gMiB2S0PTfRAZLgn3Z/6oatmcPpc6p7t29T71fNbaa1e9e1e9v9OXZ9d5d9Vbsk1ERLTH25ouICIiuivBHxHRMgn+iIiWSfBHRLRMgj8iomUS/BERLZPgj1aQdImkP2uob0m6WNIvJd3RRA1lHftKWtZU/7HuSPBHIyQtkbRC0sYdbZ+SdEuDZdVlH+BAYKbtPZsuJiLBH01aDzip6SImStK0CW4yG1hi+8U66hmJpPW61Vf0ngR/NOkrwGclbTb8BUn9ktwZYJJukfSpcvm/SfpXSedLelbSY5J+t2x/XNJKSXOH7XZLSQslPS9psaTZHfv+zfK1ZyQ9LOkPO167RNIFkm6S9CKw3wj1bivphnL7RyUdV7YfC3wbeK+kFySdNcK2SyW9u1w+uvy5dy7XPyXpunJ5fUlfk/Rk+fiapPXL1/aVtEzSKZKeAi6WtGFZ+y8l/RjYY1i/p0h6ovzzeFjSAWP8XcUUkuCPJg0CtwCfneT27wHuA94BXA5cSRFu/wk4GvimpE063n8UcDawJXAPcBlAOdy0sNzHVsCRwP+W9Fsd2/4X4M+BTYHbRqjlCmAZsC3wUeBLkg6wfSHw34Ef2t7E9hkjbLsY2Ldcfj/wGPCBjvXF5fLngb2AOcCuwJ7AFzr2sw2wBcVvGPOAM4AdysfvA7/6IJS0E3ACsIftTcvXl4xQW0xBCf5o2unAiZL6JrHtz2xfbPt14G+BWcAXbb9s+2bgFYoPgVX+wfattl+mCNH3SpoFHEIxFHOx7dds3wVcQxHgq1xv+19tv2H7pc4iyn3sA5xi+yXb91Ac5R9T8edYzJtB/z7gyx3rH+DN4D+q/PlW2h4CzhrWxxvAGeXP/x/AHwJ/bvsZ248D3+h47+vA+sDOkqbbXmL7pxXrjR6X4I9G2X4AuBE4dRKbr+hY/o9yf8PbOo/4H+/o9wXgGYoj9NnAe8oho2clPUsRstuMtO0ItgWesf18R9tSYLuKP8di4H2StgGmUXyI7S2pH/h1it9OVvWzdFgf23asDw37UNp2WN2/2tb2o8BngDOBlZKulNS5r5jCEvyxLjgDOI63BuWqL0I36mjrDOLJmLVqoRwC2gJ4kiIcF9verOOxie3/0bHtWNPYPglsIWnTjrbtgSeqFFWG8L8DfwTcWn6APEUxXHOb7Tc6+pndsen2ZdtoNS6n42cu39/Z7+W29yn3aeAvqtQbvS/BH40rg+9vKYJvVdsQRXAeLWmapE9SjFWviYMl7SPp1yjG+m8vh0BuBP6zpGMkTS8fe0h6V8X6Hwf+D/BlSRtI+h3gWMrvECpaTDHmvmpY55Zh61B8j/AFSX2StqQYJrt0jH1eBZwmaXNJM4ETV70gaSdJ+5dfDr9E8dvR6xOoN3pYgj/WFV8ENh7WdhzwJ8AvgN+iCNc1cTnFbxfPAO+mGM6hPML+PeDjFEfQT1Ec/a4/gX0fCfSX219LMda+cALbL6b44vjWUdYB/oziC/H7gPuBu8q20ZxFMbzzM+Bm4Dsdr60PnAM8TfHzbgV8bgL1Rg9TbsQSEdEuOeKPiGiZBH9ERMsk+CMiWibBHxHRMj0xkdOWW27p/v7+psuIiOgpd95559O2V7sqvieCv7+/n8HBwabLiIjoKZKWjtRe+1BPefHN3ZJuLNe3KGdBfKR83rzuGiIi4k3dGOM/CXioY/1UYJHtHYFFTG6OloiImKRag7+8TPzDFDMVrnIYsKBcXgAcXmcNERHxVnUf8X8N+FOK6WJX2dr2coDyeauRNpQ0T9KgpMGhoaGay4yIaI/agl/SIcBK23dOZnvb820P2B7o65vMVO0RETGSOs/q2Rs4VNLBwAbA2yVdCqyQNMP2ckkzgJU11hAREcPUdsRv+zTbM233U8x6+H3bRwM38OYt4OYC19dVQ0RErK6JK3fPAQ6U9AhwYLkeERFd0pULuGzfQnFjCWz/AjigG/1GRMTqMldPrDX9s7ZBUiOP/llrelfGiPboiSkbojcsXbYCT+Rmg2uRjlox/psiAsgRf0RE6yT4IyJaJsEfEdEyCf6IiJZJ8EdEtEyCPyKiZRL8EREtk+CPiGiZBH9ERMsk+CMiWibBHxHRMgn+iIiWSfBHRLRMgj8iomUS/BERLZPgj4homdqCX9IGku6QdK+kByWdVbafKekJSfeUj4PrqiEiIlZX5x24Xgb2t/2CpOnAbZK+V752vu2v1th3RESMorbgt23ghXJ1evlwXf1FREQ1tY7xS5om6R5gJbDQ9u3lSydIuk/SRZI2H2XbeZIGJQ0ODQ3VWWZERKvUGvy2X7c9B5gJ7ClpF+ACYAdgDrAcOHeUbefbHrA90NfXV2eZERGt0pWzemw/C9wCHGR7RfmB8AbwLWDPbtQQERGFOs/q6ZO0Wbm8IfBB4CeSZnS87QjggbpqiIiI1dV5Vs8MYIGkaRQfMFfZvlHSdyTNofiidwnw6RpriIiIYeo8q+c+YLcR2o+pq8+IiBhfrtyNiGiZBH9ERMsk+CMiWibBHxHRMgn+iIiWSfBHRLRMgj8iomUS/BERLZPgj4homQR/RETLJPgjIlomwR8R0TIJ/oiIlknwR0S0TII/IqJlEvwRES2T4I+IaJk677m7gaQ7JN0r6UFJZ5XtW0haKOmR8nnzumqIiIjV1XnE/zKwv+1dgTnAQZL2Ak4FFtneEVhUrkdERJfUFvwuvFCuTi8fBg4DFpTtC4DD66ohIiJWV+sYv6Rpku4BVgILbd8ObG17OUD5vFWdNURExFvVGvy2X7c9B5gJ7Clpl6rbSponaVDS4NDQUG01RkS0TVfO6rH9LHALcBCwQtIMgPJ55SjbzLc9YHugr6+vG2VGRLRCnWf19EnarFzeEPgg8BPgBmBu+ba5wPV11RAREatbr8Z9zwAWSJpG8QFzle0bJf0QuErSscDPgY/VWENERAxTW/Dbvg/YbYT2XwAH1NVvRESMLVfuRkS0TII/IqJlEvwRES2T4I+IaJkJBb+kt0l6e13FRERE/cYNfkmXS3q7pI2BHwMPS/qT+kuLiIg6VDni39n2cxSTqd0EbA8cU2dRERFRnyrBP13SdIrgv972qxSzbEZERA+qEvx/DSwBNgZulTQbeK7OoiIioj7jXrlr+xvANzqalkrar76SIiKiTqMGv6Q/Hmfb89ZyLRER0QVjHfFvWj7vBOxBMasmwB8At9ZZVERE1GfU4Le96uboNwO7236+XD8T+LuuVBcREWtdlS93twde6Vh/BeivpZqIiKhdlWmZvwPcIelaitM4j+DNm6VHRESPGTP4JQn4G+B7wPvK5k/YvrvuwiIioh5jBr9tS7rO9ruBu7pUU0RE1KjKGP+/Sdqj9koiIqIrqgT/fhTh/1NJ90m6X9J9420kaZakH0h6SNKDkk4q28+U9ISke8rHwWv6Q0RERHVVvtz90CT3/Rpwsu27JG0K3ClpYfna+ba/Osn9RkTEGqgyZcNSSbvy5pe7/2L73grbLQeWl8vPS3oI2G5Nio2IiDVXZT7+k4DLgK3Kx6WSTpxIJ5L6gd2A28umE8pho4skbT7KNvMkDUoaHBoamkh3ERExhipj/McC77F9uu3Tgb2A46p2IGkT4BrgM+W8/hcAOwBzKH4jOHek7WzPtz1ge6Cvr69qdxERMY4qwS/g9Y7118u28Tcs5vG/BrjM9ncBbK+w/brtN4BvAXtOrOSIiFgTVb7cvRi4vbxyF4obslw43kblxV8XAg/ZPq+jfUY5/g/FVcAPTKjiiIhYI1W+3D1P0i3APhRH+lWv3N2b4haN90u6p2z7HHCkpDkU0z8sAT494aojImLSxg1+SV8E/gW40PaLVXds+zZGHhK6qXp5ERGxtlUZ418CHAkMSrpD0rmSDqu3rIiIqMu4wW/7ItufpLiC91LgY+VzRET0oCpDPd8GdgZWUAz5fJRM2BYR0bOqDPW8A5gGPAs8Azxt+7U6i4qIiPpUOavnCABJ7wJ+H/iBpGm2Z9ZdXERErH1VhnoOoZin5/3A5sD3KYZ8IiKiB1WdnfNW4Ou2n6y5noiIqFmVoZ7ju1FIRER0R5UvdyMiYgpJ8EdEtMyowS9pUfn8F90rJyIi6jbWGP8MSR8ADpV0JcPm3bGdi7giInrQWMF/OnAqMBM4b9hrBvavq6iIiKjPqMFv+2rgakn/y/bZXawpIiJqVOV0zrMlHUpxARfALbZvrLesiIioS5WbrX8ZOAn4cfk4qWyLiIgeVOXK3Q8Dc8p75CJpAXA3cFqdhUVERD2qnse/Wcfyr1fZQNIsST+Q9JCkByWdVLZvIWmhpEfK580nWHNERKyBKsH/ZeBuSZeUR/t3Al+qsN1rwMm23wXsBRwvaWeKM4UW2d4RWFSuR0REl1T5cveK8mbre1Ccy3+K7acqbLccWF4uPy/pIWA74DBg3/JtC4BbgFMmUXtERExClTH+VSF+w2Q7kdQP7AbcDmxd7g/byyVtNdn9RkTExNU+V4+kTYBrgM/Yfm4C282TNChpcGhoqL4CIyJaptbglzSdIvQvs/3dsnmFpBnl6zOAlSNta3u+7QHbA319fXWWGRHRKmMGv6S3SXpgMjuWJOBC4CHbnVM+3ADMLZfnAtdPZv8RETE5YwZ/ee7+vZK2n8S+9waOAfaXdE/5OBg4BzhQ0iPAgeV6RER0SZUvd2cAD0q6A3hxVaPtQ8fayPZtDJvRs8MBlSuMiIi1qkrwn1V7FRER0TVVzuNfLGk2sKPtf5a0ETCt/tIiIqIOVSZpOw64Gvjrsmk74Loaa4qIiBpVOZ3zeIovap8DsP0IkIuuIiJ6VJXgf9n2K6tWJK1HcQeuiIjoQVWCf7GkzwEbSjoQ+Dvg7+stKyIi6lIl+E8FhoD7gU8DNwFfqLOoiIioT5Wzet4op2O+nWKI52HbGeqJiOhR4wa/pA8DfwX8lOKCrHdK+rTt79VdXERErH1VLuA6F9jP9qMAknYA/gFI8EdE9KAqY/wrV4V+6TFGmVEzIiLWfaMe8Uv6SLn4oKSbgKsoxvg/BvyoC7VFVLb+dCgmhO2u2TO3Zsnj496QLmKdMtZQzx90LK8APlAuDwG5QXqsU15+FXxZ9/vVUSu632nEGho1+G1/opuFREREd1Q5q+edwIlAf+f7x5uWOSIi1k1Vzuq5juJOWn8PvFFrNRERUbsqwf+S7W/UXklERHRFleD/uqQzgJuBl1c12r6rtqoiIqI2VYL/tynvncubQz0u10cl6SLgEIrrAHYp284EjqM4Mwjgc7ZvmnjZERExWVWC/wjgNzqnZq7oEuCbwN8Maz/f9lcnuK+IiFhLqly5ey+w2UR3bPtW4JmJbhcREfWqcsS/NfATST/irWP8kz2d8wRJ/xUYBE62/cuR3iRpHjAPYPvtt59kVxERMVyV4D9jLfZ3AXA2xXcEZ1NMAPfJkd5oez4wH2BgYCDTQEdErCVV5uNfvLY6s/2r69slfQu4cW3tOyIiqhl3jF/S85KeKx8vSXpd0nOT6UzSjI7VI4AHJrOfiIiYvCpH/Jt2rks6HNhzvO0kXQHsC2wpaRnFkNG+kuZQDPUsobiVY0REdFGVMf63sH2dpFMrvO/IEZovnGh/ERGxdlWZpO0jHatvAwYojtgjIqIHVTni75yX/zWKIZrDaqkmIiJqV2WMP/PyR0RMIWPdevH0Mbaz7bNrqCciImo21hH/iyO0bQwcC7yD4gKsiIjoMWPdevHcVcuSNgVOAj4BXElxxW1ERPSgMcf4JW0B/DFwFLAA2H20uXUiIqI3jDXG/xXgIxTz5fy27Re6VlVERNRmrCkbTga2Bb4APNkxbcPzk52yISIimjfWGH+VufojIqLHJNwjIlomwR8R0TIJ/oiIlknwR0S0TII/IqJlJjwff6z7+mdtw9JlK8Z/Y6yx9aeDpEb6nj1za5Y8/lQjfUdvS/BPQUuXrcCXdb9fHdX9Ppv28qs08mcNoKPy4R6Tk6GeiIiWqS34JV0kaaWkBzratpC0UNIj5fPmdfUfEREjq/OI/xLgoGFtpwKLbO8ILCrXIyKii2oLftu3As8Maz6MYpZPyufD6+o/IiJG1u0x/q1tLwcon7ca7Y2S5kkalDQ4NDTUtQLXpv5Z2yCp64+IiLGss2f12J5PMSU0AwMDbricScnZNRGxLur2Ef8KSTMAyueVXe4/IqL1uh38NwBzy+W5wPVd7j8iovXqPJ3zCuCHwE6Slkk6FjgHOFDSI8CB5XpERHRRbWP8to8c5aUD6uozIiLGlyt3IyJaJsEfEdEyCf6IiJZJ8EdEtMw6ewFXRIytqXsB5D4AvS/BH9GjmroXQO4D0Psy1BMR0TIJ/oiIlknwR0S0TII/IqJlEvwRES2T4I+IaJkEf0REyyT4IyJaJsEfEdEyCf6IiJZJ8EdEtEwjc/VIWgI8D7wOvGZ7oIk6IiLaqMlJ2vaz/XSD/UdEtFKGeiIiWqap4Ddws6Q7Jc0b6Q2S5kkalDQ4NDTU5fIiIqaupoJ/b9u7Ax8Cjpf0/uFvsD3f9oDtgb6+vu5XGBExRTUS/LafLJ9XAtcCezZRR0REG3U9+CVtLGnTVcvA7wEPdLuOiIi2auKsnq2Ba8t7ha4HXG77HxuoIyKilboe/LYfA3btdr8REVGY8jdb75+1DUuX5ebQERGrTPngX7psBb6smb51VDP9RkSMJRdwRUS0TII/IqJlEvwRES2T4I+IGEf/rG2Q1Mijf9Y2a/3nmfJf7kZErKlmTxJZ+2cl5og/IqJlEvwRES2T4I+IaJkEf0REyyT4IyJaJsEfEdEyCf6IiJZJ8EdEtEwu4IqICVl/OpQ3Uuq62TO3ZsnjTzXS91SS4I+ICXn5VabUVaxtlKGeiIiWaST4JR0k6WFJj0o6tYkaIiLaquvBL2ka8JfAh4CdgSMl7dztOiIi2qqJI/49gUdtP2b7FeBK4LAG6oiIaCXZ7m6H0keBg2x/qlw/BniP7ROGvW8eMK9c3Ql4eJJdbgk8Pcltm5bam9Grtfdq3ZDa6zLbdt/wxibO6hnpPLDVPn1szwfmr3Fn0qDtgTXdTxNSezN6tfZerRtSe7c1MdSzDJjVsT4TeLKBOiIiWqmJ4P8RsKOkd0r6NeDjwA0N1BER0UpdH+qx/ZqkE4B/AqYBF9l+sMYu13i4qEGpvRm9Wnuv1g2pvau6/uVuREQ0K1fuRkS0TII/IqJlpmzwS5ol6QeSHpL0oKSTmq5pIiRNk3S3pBubrmUiJG0m6WpJPyn/7N/bdE1VSfqf5b+VByRdIWmDpmsajaSLJK2U9EBH2xaSFkp6pHzevMkaRzNK7V8p/83cJ+laSZs1WOKoRqq947XPSrKkLZuobSKmbPADrwEn234XsBdwfI9NDXES8FDTRUzC14F/tP2bwK70yM8gaTvgj4AB27tQnHjw8WarGtMlwEHD2k4FFtneEVhUrq+LLmH12hcCu9j+HeD/Aqd1u6iKLmH12pE0CzgQ+Hm3C5qMKRv8tpfbvqtcfp4igLZrtqpqJM0EPgx8u+laJkLS24H3AxcC2H7F9rONFjUx6wEbSloP2Ih1+PoS27cCzwxrPgxYUC4vAA7vZk1VjVS77Zttv1au/hvF9T3rnFH+3AHOB/6UES5GXRdN2eDvJKkf2A24veFSqvoaxT+iNxquY6J+AxgCLi6Hqb4taeOmi6rC9hPAVymO2JYD/8/2zc1WNWFb214OxYEPsFXD9UzWJ4HvNV1EVZIOBZ6wfW/TtVQ15YNf0ibANcBnbD/XdD3jkXQIsNL2nU3XMgnrAbsDF9jeDXiRdXe44S3K8fDDgHcC2wIbSzq62araR9LnKYZpG7rVy8RI2gj4PHB607VMxJQOfknTKUL/MtvfbbqeivYGDpW0hGLm0v0lXdpsSZUtA5bZXvWb1dUUHwS94IPAz2wP2X4V+C7wuw3XNFErJM0AKJ9XNlzPhEiaCxwCHOXeucBoB4qDhXvL/7MzgbskbdNoVeOYssGv4qagFwIP2T6v6Xqqsn2a7Zm2+ym+XPy+7Z448rT9FPC4pJ3KpgOAHzdY0kT8HNhL0kblv50D6JEvpjvcAMwtl+cC1zdYy4RIOgg4BTjU9r83XU9Vtu+3vZXt/vL/7DJg9/L/wjprygY/xZHzMRRHzPeUj4ObLqoFTgQuk3QfMAf4UrPlVFP+lnI1cBdwP8X/jXX2UnxJVwA/BHaStEzSscA5wIGSHqE4w+ScJmsczSi1fxPYFFhY/l/9q0aLHMUotfecTNkQEdEyU/mIPyIiRpDgj4homQR/RETLJPgjIlomwR8R0TIJ/oiIlknwR0S0zP8H4XjvpvjOQYoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get number of non-zero entries\n",
    "num_emb_word_entries = np.count_nonzero(x_test, axis=1)\n",
    "\n",
    "# plot histogram to get cutoffs\n",
    "plt.title(\"Number of words\")\n",
    "plt.hist(num_emb_word_entries, color='orange', edgecolor='black')\n",
    "plt.ylabel(\"Number of Sentences with word count\")\n",
    "plt.ylabel(\"Number of words\")\n",
    "\n",
    "# split based on visual cutoffs\n",
    "short_max, medium_max = 6, 8\n",
    "x_short = []\n",
    "y_short = []\n",
    "x_medium = []\n",
    "y_medium = []\n",
    "x_long = []\n",
    "y_long = []\n",
    "\n",
    "for index, num_emb_words in enumerate(num_emb_word_entries):\n",
    "    current_word = x_test_no_emb[index]\n",
    "    current_sentiment = y_test[index]\n",
    "    if num_emb_words <= short_max:\n",
    "        x_short.append(current_word)\n",
    "        y_short.append(current_sentiment)\n",
    "    elif (num_emb_words > short_max) and (num_emb_words < medium_max):\n",
    "        x_medium.append(current_word)\n",
    "        y_medium.append(current_sentiment)\n",
    "    else:\n",
    "        x_long.append(current_word)\n",
    "        y_long.append(current_sentiment)\n",
    "        \n",
    "print(f\"short count = {len(x_short)}\")\n",
    "print(f\"medium count = {len(x_medium)}\")\n",
    "print(f\"long count = {len(x_long)}\")\n",
    "\n",
    "print(y_long)\n",
    "\n",
    "# x_short = np.reshape(x_short, (len(x_short), EMBEDDED_VEC_LENGTH, 1)) / len(voc)\n",
    "# x_medium = np.reshape(x_medium, (len(x_medium), EMBEDDED_VEC_LENGTH, 1)) / len(voc)\n",
    "# x_long = np.reshape(x_long, (len(x_long), EMBEDDED_VEC_LENGTH, 1)) / len(voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL CREATION - No Embedding\n",
    "This section outline creating models.\n",
    "\n",
    "The following are created:\n",
    "\n",
    "    1. Simple RNN\n",
    "    2. LSTM\n",
    "    3. GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 20)                440       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               2100      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,944\n",
      "Trainable params: 2,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 20)                1760      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               2100      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,264\n",
      "Trainable params: 4,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 20)                1380      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               2100      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,884\n",
      "Trainable params: 3,884\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "# Simple RNN\n",
    "######\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(SimpleRNN(20, input_shape=(x_train_no_emb.shape[1], x_train_no_emb.shape[2])))\n",
    "model_rnn.add(Dropout(0.2))\n",
    "model_rnn.add(Dense(100))\n",
    "model_rnn.add(Dense(len(set(train_labels)), activation='softmax'))\n",
    "model_rnn.summary()\n",
    "\n",
    "######\n",
    "# LSTM\n",
    "######\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(20, input_shape=(x_train_no_emb.shape[1], x_train_no_emb.shape[2])))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(Dense(100))\n",
    "model_lstm.add(Dense(len(set(train_labels)), activation='softmax'))\n",
    "model_lstm.summary()\n",
    "\n",
    "######\n",
    "# GRU\n",
    "######\n",
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(20, input_shape=(x_train_no_emb.shape[1], x_train_no_emb.shape[2])))\n",
    "model_gru.add(Dropout(0.2))\n",
    "model_gru.add(Dense(100))\n",
    "model_gru.add(Dense(len(set(train_labels)), activation='softmax'))\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 1s 11ms/step - loss: 1.2572 - acc: 0.5639\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.0761 - acc: 0.6222\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0582 - acc: 0.6222\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.0404 - acc: 0.6222\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0455 - acc: 0.6211\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.0426 - acc: 0.6222\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.0295 - acc: 0.6222\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.0334 - acc: 0.6233\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.0380 - acc: 0.6256\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.0311 - acc: 0.6233\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 1s 22ms/step - loss: 1.3571 - acc: 0.5661\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 1.2685 - acc: 0.6222\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 1.1480 - acc: 0.6222\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 1.0836 - acc: 0.6222\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 1.0618 - acc: 0.6222\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 1.0494 - acc: 0.6222\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 1.0419 - acc: 0.6222\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 1.0505 - acc: 0.6222\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 1.0456 - acc: 0.6222\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 1.0440 - acc: 0.6222\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 28ms/step - loss: 1.3504 - acc: 0.5639\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 1.2436 - acc: 0.6222\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.1136 - acc: 0.6222\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 1.0627 - acc: 0.6222\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.0556 - acc: 0.6222\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 1.0532 - acc: 0.6222\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.0478 - acc: 0.6222\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.0447 - acc: 0.6222\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 1.0427 - acc: 0.6222\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.0440 - acc: 0.6222\n"
     ]
    }
   ],
   "source": [
    "MODELS = {\"model_rnn\" : model_rnn,\n",
    "          \"model_lstm\" : model_lstm,\n",
    "          \"model_gru\" : model_gru\n",
    "         }\n",
    "\n",
    "for model_name, model in MODELS.items():\n",
    "    ## Train the model \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "    model.fit(x_train_no_emb, y_train, batch_size=100, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9227 - acc: 0.6635\n",
      "recall : 0.6634615384615384; precisicion : 0.6634615384615384\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9282 - acc: 0.6635\n",
      "recall : 0.6634615384615384; precisicion : 0.6634615384615384\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9267 - acc: 0.6635\n",
      "recall : 0.6634615384615384; precisicion : 0.6634615384615384\n"
     ]
    }
   ],
   "source": [
    "# test the models\n",
    "for model_name, model in MODELS.items():\n",
    "    # obtain metrics\n",
    "    accuracy = model.evaluate(x_test_no_emb, y_test, return_dict=True)['acc']\n",
    "    predictions = np.argmax(model.predict(x_test_no_emb), axis=1)\n",
    "    recall = recall_score(predictions, y_test, average='micro')\n",
    "    precision = precision_score(predictions, y_test, average='micro')\n",
    "    \n",
    "    print(f\"recall : {recall}; precisicion : {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7543 - acc: 0.7750\n",
      "test index : 0\n",
      "recall : 0.775; precisicion : 0.775\n",
      "predicted : [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2]\n",
      "truth : [2 2 2 0 0 2 2 2 2 2 0 2 0 2 2 1 2 2 2 2 2 2 0 2 2 0 2 2 2 1 2 2 2 2 0 2 2\n",
      " 2 2 2]\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7754 - acc: 0.7750\n",
      "test index : 0\n",
      "recall : 0.775; precisicion : 0.775\n",
      "predicted : [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2]\n",
      "truth : [2 2 2 0 0 2 2 2 2 2 0 2 0 2 2 1 2 2 2 2 2 2 0 2 2 0 2 2 2 1 2 2 2 2 0 2 2\n",
      " 2 2 2]\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7690 - acc: 0.7750\n",
      "test index : 0\n",
      "recall : 0.775; precisicion : 0.775\n",
      "predicted : [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2]\n",
      "truth : [2 2 2 0 0 2 2 2 2 2 0 2 0 2 2 1 2 2 2 2 2 2 0 2 2 0 2 2 2 1 2 2 2 2 0 2 2\n",
      " 2 2 2]\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0007 - acc: 0.6250\n",
      "test index : 1\n",
      "recall : 0.625; precisicion : 0.625\n",
      "predicted : [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "truth : [2 2 1 2 2 1 2 1 1 2 0 2 2 2 2 1 2 2 2 2 0 1 1 2]\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9971 - acc: 0.6250\n",
      "test index : 1\n",
      "recall : 0.625; precisicion : 0.625\n",
      "predicted : [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "truth : [2 2 1 2 2 1 2 1 1 2 0 2 2 2 2 1 2 2 2 2 0 1 1 2]\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9961 - acc: 0.6250\n",
      "test index : 1\n",
      "recall : 0.625; precisicion : 0.625\n",
      "predicted : [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "truth : [2 2 1 2 2 1 2 1 1 2 0 2 2 2 2 1 2 2 2 2 0 1 1 2]\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0443 - acc: 0.5750\n",
      "test index : 2\n",
      "recall : 0.575; precisicion : 0.575\n",
      "predicted : [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2]\n",
      "truth : [1 2 2 2 0 1 2 2 0 2 0 1 2 0 2 1 2 0 0 0 2 1 1 2 2 2 0 2 1 0 2 2 2 2 0 2 2\n",
      " 2 2 2]\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0397 - acc: 0.5750\n",
      "test index : 2\n",
      "recall : 0.575; precisicion : 0.575\n",
      "predicted : [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2]\n",
      "truth : [1 2 2 2 0 1 2 2 0 2 0 1 2 0 2 1 2 0 0 0 2 1 1 2 2 2 0 2 1 0 2 2 2 2 0 2 2\n",
      " 2 2 2]\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0429 - acc: 0.5750\n",
      "test index : 2\n",
      "recall : 0.575; precisicion : 0.575\n",
      "predicted : [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2]\n",
      "truth : [1 2 2 2 0 1 2 2 0 2 0 1 2 0 2 1 2 0 0 0 2 1 1 2 2 2 0 2 1 0 2 2 2 2 0 2 2\n",
      " 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# test the models\n",
    "x_TESTS = [x_short, x_medium, x_long]\n",
    "y_TESTS = [y_short, y_medium, y_long]\n",
    "\n",
    "for ind, x_test_divided in enumerate(x_TESTS):\n",
    "    x_test_divided = np.array(x_test_divided)\n",
    "    y_test_divided = np.array(y_TESTS[ind])\n",
    "    for model_name, model in MODELS.items():\n",
    "        # obtain metrics\n",
    "        accuracy = model.evaluate(x_test_divided, y_test_divided, return_dict=True)['acc']\n",
    "        predictions = np.argmax(model.predict(x_test_divided), axis=1)\n",
    "        recall = recall_score(predictions, y_test_divided, average='micro')\n",
    "        precision = precision_score(predictions, y_test_divided, average='micro')\n",
    "\n",
    "        print(f\"test index : {ind}\")\n",
    "        print(f\"recall : {recall}; precisicion : {precision}\")\n",
    "        print(f\"predicted : {predictions}\")\n",
    "        print(f\"truth : {y_test_divided}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMBEDDINGS\n",
    "The following section is focused on creating embeddings for the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following were used to download the word embeddings for GLOVE \n",
    "\n",
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# !unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "## Read the embeddings in the pretrained model (we are using the 100D version of GloVe)\n",
    "#####\n",
    "# COPIED FROM LECTURE\n",
    "####\n",
    "import os\n",
    "path_to_glove_file = \"glove.6B.100d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 2101 words (222 misses)\n"
     ]
    }
   ],
   "source": [
    "## Create \"embedding_matrix\" to index our vocabulary using the GloVe model\n",
    "#####\n",
    "# COPIED FROM LECTURE\n",
    "####\n",
    "num_tokens = len(voc) \n",
    "embedding_dim = 100 ## 100 dimensions\n",
    "hits = 0 ## number of words that were found in the pretrained model\n",
    "misses = 0 ## number of words that were missing in the pretrained model\n",
    "\n",
    "# Prepare embedding matrix for our word list\n",
    "embedding_matrix_glove = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix_glove[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the model\n",
    "glove_input_file = 'glove.6B.100d.txt'\n",
    "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
    "# glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "embeddings_index = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 2101 words (222 misses)\n"
     ]
    }
   ],
   "source": [
    "## Create \"embedding_matrix\" to index our vocabulary using the word2vec model\n",
    "#####\n",
    "# COPIED FROM LECTURE\n",
    "####\n",
    "num_tokens = len(voc) \n",
    "embedding_dim = 100 ## 100 dimensions\n",
    "hits = 0 ## number of words that were found in the pretrained model\n",
    "misses = 0 ## number of words that were missing in the pretrained model\n",
    "\n",
    "# Prepare embedding matrix for our word list\n",
    "embedding_matrix_w2v = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in embeddings_index:\n",
    "        embedding_vector = embeddings_index[word]\n",
    "    else:\n",
    "        embedding_vector = None\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix_w2v[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL CREATION - with Embeddings\n",
    "This section outline creating models.\n",
    "\n",
    "The following models are:\n",
    "\n",
    "    1. LSTM\n",
    "    2. Bidirectional LSTM (for FUN!)\n",
    "\n",
    "With the following embeddings:\n",
    "\n",
    "    1. GloVe\n",
    "    2. word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Glove embedded Layer\n",
    "#####\n",
    "glove_embedding_layer = Embedding(num_tokens, embedding_dim,\n",
    "                                  embeddings_initializer= Constant(embedding_matrix_glove), \n",
    "                                  trainable=False)\n",
    "#####\n",
    "# word2vec embedded Layer\n",
    "#####\n",
    "w2v_embedding_layer = Embedding(num_tokens, embedding_dim,\n",
    "                                  embeddings_initializer= Constant(embedding_matrix_w2v), \n",
    "                                  trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 100)         232300    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20)                9680      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 242,064\n",
      "Trainable params: 9,764\n",
      "Non-trainable params: 232,300\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, None, 100)         232300    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 20)                9680      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 242,064\n",
      "Trainable params: 9,764\n",
      "Non-trainable params: 232,300\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 100)         232300    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 40)         19360     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 40)               9760      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4)                 164       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 261,584\n",
      "Trainable params: 29,284\n",
      "Non-trainable params: 232,300\n",
      "_________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, None, 100)         232300    \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, None, 40)         19360     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 40)               9760      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 164       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 261,584\n",
      "Trainable params: 29,284\n",
      "Non-trainable params: 232,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "# Simple LSTM - with GloVe\n",
    "######\n",
    "int_sequences_input = Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = glove_embedding_layer(int_sequences_input)\n",
    "x = layers.LSTM(20)(embedded_sequences)\n",
    "preds = layers.Dense(len(set(train_labels)), activation=\"softmax\")(x)\n",
    "model_lstm_glove = Model(int_sequences_input, preds)\n",
    "model_lstm_glove.summary()\n",
    "######\n",
    "# Simple LSTM - with word2vec\n",
    "######\n",
    "int_sequences_input = Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = w2v_embedding_layer(int_sequences_input)\n",
    "x = layers.LSTM(20)(embedded_sequences)\n",
    "preds = layers.Dense(len(set(train_labels)), activation=\"softmax\")(x)\n",
    "model_lstm_w2v = Model(int_sequences_input, preds)\n",
    "model_lstm_w2v.summary()\n",
    "\n",
    "######\n",
    "# Bidirectional LSTM - with GloVe\n",
    "######\n",
    "int_sequences_input = Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = glove_embedding_layer(int_sequences_input)\n",
    "x = layers.Bidirectional(layers.LSTM(20, return_sequences=True))(embedded_sequences)\n",
    "x = layers.Bidirectional(layers.LSTM(20))(x)\n",
    "preds = layers.Dense(len(set(train_labels)), activation=\"softmax\")(x)\n",
    "model_lstm_glove = Model(int_sequences_input, preds)\n",
    "model_lstm_glove.summary()\n",
    "######\n",
    "# Bidirectional LSTM - with word2vec\n",
    "######\n",
    "int_sequences_input = Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = w2v_embedding_layer(int_sequences_input)\n",
    "x = layers.Bidirectional(layers.LSTM(20, return_sequences=True))(embedded_sequences)\n",
    "x = layers.Bidirectional(layers.LSTM(20))(x)\n",
    "preds = layers.Dense(len(set(train_labels)), activation=\"softmax\")(x)\n",
    "model_lstm_w2v = Model(int_sequences_input, preds)\n",
    "model_lstm_w2v.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 6s 276ms/step - loss: 1.3195 - acc: 0.4473 - val_loss: 1.1834 - val_acc: 0.6571\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 1.1353 - acc: 0.6222 - val_loss: 1.0222 - val_acc: 0.6571\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 1.0644 - acc: 0.6222 - val_loss: 0.9648 - val_acc: 0.6571\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.0469 - acc: 0.6222 - val_loss: 0.9408 - val_acc: 0.6571\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 1.0315 - acc: 0.6222 - val_loss: 0.9363 - val_acc: 0.6571\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.0254 - acc: 0.6222 - val_loss: 0.9245 - val_acc: 0.6571\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 1.0131 - acc: 0.6222 - val_loss: 0.9158 - val_acc: 0.6571\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.9971 - acc: 0.6222 - val_loss: 0.9104 - val_acc: 0.6571\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.9748 - acc: 0.6222 - val_loss: 0.8908 - val_acc: 0.6571\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.9443 - acc: 0.6222 - val_loss: 0.8668 - val_acc: 0.6571\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 6s 266ms/step - loss: 1.2795 - acc: 0.5213 - val_loss: 1.1472 - val_acc: 0.6571\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 1.1251 - acc: 0.6222 - val_loss: 1.0003 - val_acc: 0.6571\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 1.0556 - acc: 0.6222 - val_loss: 0.9492 - val_acc: 0.6571\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.0420 - acc: 0.6222 - val_loss: 0.9289 - val_acc: 0.6571\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 1.0297 - acc: 0.6222 - val_loss: 0.9189 - val_acc: 0.6571\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 1.0180 - acc: 0.6222 - val_loss: 0.9134 - val_acc: 0.6571\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 1.0047 - acc: 0.6222 - val_loss: 0.9109 - val_acc: 0.6571\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.9878 - acc: 0.6222 - val_loss: 0.9036 - val_acc: 0.6571\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.9664 - acc: 0.6222 - val_loss: 0.8891 - val_acc: 0.6571\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.9365 - acc: 0.6222 - val_loss: 0.8671 - val_acc: 0.6571\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 6s 272ms/step - loss: 0.9087 - acc: 0.6334 - val_loss: 0.8395 - val_acc: 0.6571\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.8693 - acc: 0.6603 - val_loss: 0.8107 - val_acc: 0.6667\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.8318 - acc: 0.6715 - val_loss: 0.7815 - val_acc: 0.6857\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.7963 - acc: 0.6917 - val_loss: 0.7577 - val_acc: 0.7143\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.7638 - acc: 0.7096 - val_loss: 0.7357 - val_acc: 0.7048\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.7392 - acc: 0.7231 - val_loss: 0.7464 - val_acc: 0.7048\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.6985 - acc: 0.7388 - val_loss: 0.7219 - val_acc: 0.7048\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.6715 - acc: 0.7444 - val_loss: 0.7353 - val_acc: 0.7143\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.6439 - acc: 0.7500 - val_loss: 0.7175 - val_acc: 0.7238\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.6171 - acc: 0.7657 - val_loss: 0.7425 - val_acc: 0.7333\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 6s 281ms/step - loss: 0.9091 - acc: 0.6345 - val_loss: 0.8591 - val_acc: 0.6571\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.8784 - acc: 0.6379 - val_loss: 0.8334 - val_acc: 0.6667\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.8455 - acc: 0.6872 - val_loss: 0.8191 - val_acc: 0.6762\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.8177 - acc: 0.6760 - val_loss: 0.8193 - val_acc: 0.6762\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.7818 - acc: 0.7108 - val_loss: 0.7899 - val_acc: 0.6762\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.7537 - acc: 0.7276 - val_loss: 0.8043 - val_acc: 0.6762\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.7259 - acc: 0.7433 - val_loss: 0.7975 - val_acc: 0.6667\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.6984 - acc: 0.7556 - val_loss: 0.8015 - val_acc: 0.6762\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.6728 - acc: 0.7601 - val_loss: 0.7637 - val_acc: 0.6952\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.6524 - acc: 0.7758 - val_loss: 0.8284 - val_acc: 0.6762\n"
     ]
    }
   ],
   "source": [
    "emb_MODELS = {\"LSTM (glove)\" : model_lstm_glove,\n",
    "          \"LSTM (word2vec)\" : model_lstm_w2v,\n",
    "          \"Bi-LSTM (glove)\" : model_lstm_glove,\n",
    "          \"Bi-LSTM (word2vec)\" : model_lstm_w2v,\n",
    "         }\n",
    "for model_name, model in emb_MODELS.items():\n",
    "    ## Train the model \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0564 - acc: 0.6827\n",
      "recall : 0.6826923076923077; precisicion : 0.6826923076923077\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9826 - acc: 0.6923\n",
      "recall : 0.6923076923076923; precisicion : 0.6923076923076923\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0564 - acc: 0.6827\n",
      "recall : 0.6826923076923077; precisicion : 0.6826923076923077\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9826 - acc: 0.6923\n",
      "recall : 0.6923076923076923; precisicion : 0.6923076923076923\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Train the model \n",
    "for model_name, model in emb_MODELS.items():\n",
    "    # obtain metrics\n",
    "    accuracy = model.evaluate(x_test, y_test, return_dict=True)['acc']\n",
    "    predictions = np.argmax(model.predict(x_test), axis=1)\n",
    "    recall = recall_score(predictions, y_test, average='micro')\n",
    "    precision = precision_score(predictions, y_test, average='micro')\n",
    "    conf_matrix = confusion_matrix(predictions, y_test)\n",
    "    print(f\"recall : {recall}; precisicion : {precision}\")\n",
    "    plt.imshow(conf_matrix)\n",
    "    labels = index2meaning.keys()\n",
    "    plt.title(f\"Confusion Matrix for {model_name}\")\n",
    "    plt.yticks(range(len(labels)), labels)\n",
    "    plt.xticks(range(len(labels)), labels)\n",
    "    plt.ylabel(\"TRUE\")\n",
    "    plt.xlabel(\"PREDICTED\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
