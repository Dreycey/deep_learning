{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "import pickle\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "# image processing\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "# tenserflow imports\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dense, Multiply, Concatenate, Average\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras import Input, Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "The following parameters allow for adjusting the size of the bag-of-words embedding, as well as other various factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_BAGOFWORDS_SIZE = 2000\n",
    "g_EMBIMG_SIZE = 1000 # known from the  RESNET50 output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tokenizers for the Questions and Answers.\n",
    "\n",
    "Of note, this is a bag-of-words (BoW) model as seen in Agrawal et al. \n",
    "\n",
    "\n",
    "This was implimented by hand to allow for flecibility in testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionTokenizer:\n",
    "    \"\"\" Question Tokenizer \"\"\"\n",
    "    \n",
    "    def __init__(self, q_string_list, a_string_list, vector_size, percent_q=0.90):\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.vector_size = vector_size\n",
    "        self.percent_q = percent_q\n",
    "        self.initialize(q_string_list, a_string_list)\n",
    "        \n",
    "    def tokenize(self, string):\n",
    "        \"\"\"\n",
    "        This method will turn a string of words into \n",
    "        a bag-of-words vector.\n",
    "        \n",
    "        if inherited, use change this.\n",
    "        \"\"\"\n",
    "        token = np.zeros((self.vector_size))\n",
    "        word_list = string.split(\" \")\n",
    "        index_count = {}\n",
    "        for word in word_list:\n",
    "            if word in self.word2index:\n",
    "                index = self.word2index[word]\n",
    "                if index in index_count:\n",
    "                    index_count[index] += 1\n",
    "                else:\n",
    "                    index_count[index] = 1\n",
    "        for index, count in index_count.items():\n",
    "            token[index] = count / max(index_count.values())\n",
    "        return token\n",
    "    \n",
    "    def initialize(self, q_string_list, a_string_list):\n",
    "        \"\"\" \n",
    "        description: creates the underlying datastructure\n",
    "        input: string list for questions, string list for answers\n",
    "        output: count dictionary\n",
    "        \"\"\"\n",
    "        # Obtain words only.\n",
    "        q_word_list = []\n",
    "        for string in q_string_list:\n",
    "            q_word_list += string.split(\" \")\n",
    "        a_word_list = []\n",
    "        for string in a_string_list:\n",
    "            a_word_list += string.split(\" \")\n",
    "        # obtain top words. \n",
    "        # Note: both answers and questions used here due to Agrawal et al. fig 5\n",
    "        print(\"finding top words\")\n",
    "        q_word_top = self.__retrieve_top_N(q_word_list, int(self.vector_size * self.percent_q))\n",
    "        a_word_top = self.__retrieve_top_N(a_word_list, int(self.vector_size * (1-self.percent_q)))\n",
    "        print(\"\\t DONE!\")\n",
    "        \n",
    "        # add to mappings.\n",
    "        print(\"making mappings\")\n",
    "        self.__make_mappings(q_word_top + a_word_top)\n",
    "        print(\"\\t DONE!\")\n",
    "    \n",
    "    def __retrieve_top_N(self, word_list, N):\n",
    "        \"\"\"\n",
    "        description: retrieves the top N words in a count dictionary.\n",
    "        input: number of words to grab, dictionary of word counts.\n",
    "        output: list of top N words.\n",
    "        \"\"\"\n",
    "        # get dictionary count\n",
    "        count_dictionary = self.__count_word_frequency(word_list)\n",
    "        # return top N\n",
    "        tuple_map = [(k,v) for k, v in count_dictionary.items()]\n",
    "        tuple_map.sort(key=lambda a: a[1], reverse=True)\n",
    "        top_N = [i[0] for i in tuple_map[:N]]\n",
    "        return top_N\n",
    "    \n",
    "    def __count_word_frequency(self, string_list):\n",
    "        \"\"\" \n",
    "        description: expects list of strings.\n",
    "        input: string list\n",
    "        output: count dictionary\n",
    "        \"\"\"\n",
    "        word_count = {}\n",
    "        for word in string_list:\n",
    "            if word == '': continue #skip white space\n",
    "            if word in word_count:\n",
    "                word_count[word] += 1\n",
    "            else:\n",
    "                word_count[word] = 1\n",
    "        return word_count\n",
    "    \n",
    "    def __make_mappings(self, word_list):\n",
    "        \"\"\"\n",
    "        description: given a word list, this method makes mappings\n",
    "        input: creates the vector mappings.\n",
    "        output: None\n",
    "        \"\"\"\n",
    "        for index, word in enumerate(word_list):\n",
    "            self.word2index[word] = index\n",
    "            self.index2word[index] = word\n",
    "            \n",
    "            \n",
    "class AnswerTokenizer(QuestionTokenizer):\n",
    "    \"\"\" Tokenizer for the Answers\"\"\"\n",
    "    \n",
    "    def __init__(self, a_string_list, vector_size, q_string_list=[], percent_q=0.00):\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.vector_size = vector_size\n",
    "        self.percent_q = percent_q\n",
    "        self.initialize(q_string_list, a_string_list)\n",
    "        \n",
    "    def tokenize(self, string):\n",
    "        \"\"\"\n",
    "        This method will turn a string of words into \n",
    "        a TOKENIZED (not bag of words) vector.\n",
    "        \n",
    "        if inherited, use change this.\n",
    "        \"\"\"\n",
    "        token = np.zeros((self.vector_size))\n",
    "        word_list = string.split(\" \")\n",
    "        index_count = {}\n",
    "        for word in word_list:\n",
    "            if word in self.word2index:\n",
    "                index = self.word2index[word]\n",
    "                if index in index_count:\n",
    "                    index_count[index] += 1\n",
    "                else:\n",
    "                    index_count[index] = 1\n",
    "        for index, count in index_count.items():\n",
    "            token[index] = 1\n",
    "        return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding top words\n",
      "\t DONE!\n",
      "making mappings\n",
      "\t DONE!\n",
      "{'who': 0, 'are': 1, 'you': 2}\n",
      "finding top words\n",
      "\t DONE!\n",
      "making mappings\n",
      "\t DONE!\n"
     ]
    }
   ],
   "source": [
    "test_q = [\"who are you\", \"who am I\", \"how are you\"]\n",
    "test_a = [\"no\", \"yes\", \"yes \"]\n",
    "\n",
    "# make tokenizer\n",
    "q_tokenizer = QuestionTokenizer(test_q, test_a, 4)\n",
    "print(q_tokenizer.word2index)\n",
    "\n",
    "# test tokenization\n",
    "q_tokenizer.tokenize('yes')\n",
    "q_tokenizer.tokenize('who you')\n",
    "assert all(q_tokenizer.tokenize('you') == [0., 0., 1., 0.])\n",
    "\n",
    "\n",
    "# test answer tokenization\n",
    "a_tokenizer = AnswerTokenizer(test_a, 2)\n",
    "assert all(a_tokenizer.tokenize('yes no no') == [1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-House Methods\n",
    "\n",
    "1. process_data() - this method preprocesses the input data url, returning vectors ready for the downstream NN.\n",
    "    2. data2rawlists() - this method, used by process_data(), parses the json URL and turns data into lists.\n",
    "    3. process_image_urls() - this method, used by process_data(), converts the image urls into embedded vectors using an input model. Default model is the ResNet50.\n",
    "        4. imageurl2embedding() - uses model to convert image URL.\n",
    "        5. transform_image() - gets image into correct shape for ResNet (easier to train than VGG)\n",
    "    6. process_q_or_a() - process a list of questions or answers using an in-house tokenizer than creates a bag of words model similair to the described implimentation by Agrawal et al. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_url, count, q_tokenizer, a_tokenizer):\n",
    "    \"\"\"\n",
    "    MAJOR PREPROCESS METHOD.\n",
    "    \n",
    "    This processes a train, validate, or test annotation file\n",
    "    and saves the results as a local pickle object. \n",
    "    \n",
    "    This allows for caching, so embeddings only have to be made once per size.\n",
    "    \"\"\"\n",
    "    # type\n",
    "    data_type = data_url.split(\"/\")[-1].replace(\".json\", \"\")\n",
    "    # turn json info into lists.\n",
    "    print(\"Processing json \\n\")\n",
    "    raw_imgurl_list, raw_questions_list, raw_answers_list = data2rawlists(data_url, count)\n",
    "    print(\"\\t DONE \\n\\n\")\n",
    "    \n",
    "    # process questions and answers.\n",
    "    print(\"Making Tokenizers \\n\")\n",
    "    ## use Q Tokenizers\n",
    "    processed_qs = process_q_or_a(raw_questions_list, q_tokenizer)\n",
    "    ## use A Tokenizers\n",
    "    processed_as = process_q_or_a(raw_answers_list, a_tokenizer)    \n",
    "    answer_count = len(a_tokenizer.word2index.keys())\n",
    "    print(\"\\t DONE \\n\\n\")\n",
    "    \n",
    "    # process images\n",
    "    print(\"Making Images \\n\")\n",
    "    image_emb_file = f\"{data_type}_{count}_images.pickle\"\n",
    "    if exists(image_emb_file):\n",
    "        image_embeddings = pickle.load(open(image_emb_file, \"rb\" ))\n",
    "    else:\n",
    "        image_embeddings = process_image_urls(raw_imgurl_list)\n",
    "        pickle.dump(image_embeddings, open(image_emb_file, \"wb\" ))\n",
    "    print(\"\\t DONE \\n\\n\")\n",
    "    \n",
    "    return np.array(image_embeddings), np.array(processed_qs), np.array(processed_as), answer_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a data set and return raw lists.\n",
    "def data2rawlists(data, N, img_dir=\"https://vizwiz.cs.colorado.edu//VizWiz_visualization_img/\"):\n",
    "    \"\"\" returns list of all data into lists \"\"\"\n",
    "    raw_imgurl_list, raw_questions_list, raw_answers_list = [], [], []\n",
    "    split_val_data = requests.get(data, allow_redirects=True)\n",
    "    data = split_val_data.json()\n",
    "    for index in range(N):\n",
    "        #index data\n",
    "        vq = data[index]\n",
    "        # get/store image URL\n",
    "        image_name = vq['image']\n",
    "        image_url = img_dir + image_name\n",
    "        raw_imgurl_list.append(image_url)\n",
    "        # get/store Q string\n",
    "        question = vq['question']\n",
    "        raw_questions_list.append(question)\n",
    "        # get/store answers\n",
    "        if 'answers' in vq:\n",
    "            answers = vq['answers']\n",
    "            label = answers[0]['answer']\n",
    "            raw_answers_list.append(label)\n",
    "    return raw_imgurl_list, raw_questions_list, raw_answers_list \n",
    "\n",
    "# example usage\n",
    "# raw_imgurl_list, raw_questions_list, raw_answers_list = data2rawlists(data, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = resnet50.ResNet50()\n",
    "\n",
    "def process_image_urls(img_list):\n",
    "    \"\"\"\n",
    "    processes list of images into list of embeddings\n",
    "    \"\"\"\n",
    "    img_emb = []\n",
    "    for count, img in enumerate(img_list):\n",
    "        img_emb.append(imageurl2embedding(img)[0])\n",
    "        if count % 10 == 0:\n",
    "            print(f\"working on #: {count}\")\n",
    "    return img_emb\n",
    "\n",
    "def imageurl2embedding(unprocess_img_url, model=resnet_model):\n",
    "    \"\"\"\n",
    "    uses model to make embedding\n",
    "    \"\"\"\n",
    "    x = transform_image(unprocess_img_url)\n",
    "    embedding = model.predict(x)\n",
    "    return embedding\n",
    "\n",
    "def transform_image(unprocess_img_url, new_shape=(224, 224)):\n",
    "    \"\"\"\n",
    "    gets image into correct shape for ResNet (easier to train than VGG)\n",
    "    \"\"\"\n",
    "    img = io.imread(unprocess_img_url)\n",
    "#     visualize_image(unprocess_img_url)\n",
    "    x = cv2.resize(img, new_shape)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = resnet50.preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_q_or_a(q_a_list, tokenizer):\n",
    "    \"\"\"\n",
    "    processes list of questions or answers.\n",
    "    \"\"\"\n",
    "    string_emb_list = []\n",
    "    for count, string in enumerate(q_a_list):\n",
    "        string_emb_list.append(tokenizer.tokenize(string))\n",
    "        if count % 1000 == 0:\n",
    "            print(f\"working on #: {count}\")\n",
    "    return string_emb_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Steps\n",
    "\n",
    "Depending on whether or not it has been ran for the images, this step may be slow or fast. It's suggested to run with a low amount first to see how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding top words\n",
      "\t DONE!\n",
      "making mappings\n",
      "\t DONE!\n",
      "finding top words\n",
      "\t DONE!\n",
      "making mappings\n",
      "\t DONE!\n",
      "Processing json \n",
      "\n",
      "\t DONE \n",
      "\n",
      "\n",
      "Making Tokenizers \n",
      "\n",
      "working on #: 0\n",
      "working on #: 1000\n",
      "working on #: 2000\n",
      "working on #: 3000\n",
      "working on #: 4000\n",
      "working on #: 5000\n",
      "working on #: 6000\n",
      "working on #: 7000\n",
      "working on #: 8000\n",
      "working on #: 9000\n",
      "working on #: 0\n",
      "working on #: 1000\n",
      "working on #: 2000\n",
      "working on #: 3000\n",
      "working on #: 4000\n",
      "working on #: 5000\n",
      "working on #: 6000\n",
      "working on #: 7000\n",
      "working on #: 8000\n",
      "working on #: 9000\n",
      "\t DONE \n",
      "\n",
      "\n",
      "Making Images \n",
      "\n",
      "\t DONE \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess Training Data\n",
    "data_url = \"https://ivc.ischool.utexas.edu/VizWiz_final/vqa_data/Annotations/train.json\"\n",
    "\n",
    "number_of_training = 10000\n",
    "# training data used to create tokenizer\n",
    "raw_imgurl_list, raw_questions_list, raw_answers_list = data2rawlists(data_url, number_of_training)\n",
    "q_tokenizer = QuestionTokenizer(raw_questions_list, raw_answers_list, g_BAGOFWORDS_SIZE)\n",
    "a_tokenizer = AnswerTokenizer(raw_answers_list, len(raw_answers_list))\n",
    "\n",
    "train_processed_img, train_processed_q, train_processed_a, train_answers_count = process_data(data_url, number_of_training, q_tokenizer, a_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(10000, 2000)\n",
      "(10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(train_processed_img.shape)\n",
    "print(train_processed_q.shape)\n",
    "print(train_processed_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing json \n",
      "\n",
      "\t DONE \n",
      "\n",
      "\n",
      "Making Tokenizers \n",
      "\n",
      "working on #: 0\n",
      "working on #: 1000\n",
      "working on #: 0\n",
      "working on #: 1000\n",
      "\t DONE \n",
      "\n",
      "\n",
      "Making Images \n",
      "\n",
      "\t DONE \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess validation Data\n",
    "data_url = \"https://ivc.ischool.utexas.edu/VizWiz_final/vqa_data/Annotations/val.json\"\n",
    "val_processed_img, val_processed_q, val_processed_a, val_answers_count = process_data(data_url, 2000, q_tokenizer, a_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1000)\n",
      "(2000, 2000)\n",
      "(2000, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(val_processed_img.shape)\n",
    "print(val_processed_q.shape)\n",
    "print(val_processed_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing json \n",
      "\n",
      "\t DONE \n",
      "\n",
      "\n",
      "Making Tokenizers \n",
      "\n",
      "working on #: 0\n",
      "\t DONE \n",
      "\n",
      "\n",
      "Making Images \n",
      "\n",
      "\t DONE \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess Testing Data\n",
    "data_url = \"https://ivc.ischool.utexas.edu/VizWiz_final/vqa_data/Annotations/test.json\"\n",
    "test_processed_img, test_processed_q, test_processed_a, test_answers_count = process_data(data_url, 1000, q_tokenizer, a_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Models.\n",
    "\n",
    "Here 3 different VQA models are created. Note that the Image Channel has beem processed by this point using a \"frozen\" copy of ResNet50, and the questions are really just a bag-of-words model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Multiply, Concatenate, Average\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras import Input, Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_58\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_134 (InputLayer)         [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " input_135 (InputLayer)         [(None, 2000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_224 (Dense)              (None, 1000)         1001000     ['input_134[0][0]']              \n",
      "                                                                                                  \n",
      " dense_225 (Dense)              (None, 1000)         2001000     ['input_135[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_19 (Multiply)         (None, 1000)         0           ['dense_224[0][0]',              \n",
      "                                                                  'dense_225[0][0]']              \n",
      "                                                                                                  \n",
      " dense_226 (Dense)              (None, 1000)         1001000     ['multiply_19[0][0]']            \n",
      "                                                                                                  \n",
      " dense_227 (Dense)              (None, 10000)        10010000    ['dense_226[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,013,000\n",
      "Trainable params: 14,013,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MODEL 1\n",
    "\n",
    "# get input ready\n",
    "img_in_layer = Input(shape=(g_EMBIMG_SIZE,))\n",
    "bow_in_layer = Input(shape=(g_BAGOFWORDS_SIZE,))\n",
    "# send through FF\n",
    "EMBEDDING_SIZE = 1000\n",
    "img_in_emb_layer = Dense(EMBEDDING_SIZE, activation=\"tanh\")(img_in_layer)\n",
    "bow_in_emb_layer = Dense(EMBEDDING_SIZE, activation=\"tanh\")(bow_in_layer)\n",
    "# combine output from first FFs\n",
    "mix_layer = Multiply()([img_in_emb_layer, bow_in_emb_layer ])\n",
    "# FF on combined information\n",
    "linear_layer = Dense(1000, activation=\"tanh\")(mix_layer)\n",
    "out_layer = Dense(train_processed_a.shape[1], activation=softmax)(linear_layer)\n",
    "\n",
    "\n",
    "# create model\n",
    "model_1 = Model(inputs=[img_in_layer, bow_in_layer], outputs=out_layer)\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_59\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_136 (InputLayer)         [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " input_137 (InputLayer)         [(None, 2000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_228 (Dense)              (None, 1000)         1001000     ['input_136[0][0]']              \n",
      "                                                                                                  \n",
      " dense_229 (Dense)              (None, 1000)         2001000     ['input_137[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 2000)         0           ['dense_228[0][0]',              \n",
      "                                                                  'dense_229[0][0]']              \n",
      "                                                                                                  \n",
      " dense_230 (Dense)              (None, 1000)         2001000     ['concatenate_17[0][0]']         \n",
      "                                                                                                  \n",
      " dense_231 (Dense)              (None, 10000)        10010000    ['dense_230[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,013,000\n",
      "Trainable params: 15,013,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MODEL 2\n",
    "\n",
    "# get input ready\n",
    "img_in_layer = Input(shape=(g_EMBIMG_SIZE,))\n",
    "bow_in_layer = Input(shape=(g_BAGOFWORDS_SIZE,))\n",
    "# send through FF\n",
    "img_in_emb_layer = Dense(EMBEDDING_SIZE, activation=\"tanh\")(img_in_layer)\n",
    "bow_in_emb_layer = Dense(EMBEDDING_SIZE, activation=\"tanh\")(bow_in_layer)\n",
    "# combine output from first FFs\n",
    "mix_layer = Concatenate(axis=1)([img_in_emb_layer, bow_in_emb_layer ])\n",
    "# FF on combined information\n",
    "linear_layer = Dense(1000, activation=\"tanh\")(mix_layer)\n",
    "out_layer = Dense(train_processed_a.shape[1], activation=softmax)(linear_layer)\n",
    "\n",
    "# create model\n",
    "model_2 = Model(inputs=[img_in_layer, bow_in_layer], outputs=out_layer)\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_60\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_138 (InputLayer)         [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " input_139 (InputLayer)         [(None, 2000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_232 (Dense)              (None, 1000)         1001000     ['input_138[0][0]']              \n",
      "                                                                                                  \n",
      " dense_233 (Dense)              (None, 1000)         2001000     ['input_139[0][0]']              \n",
      "                                                                                                  \n",
      " average_20 (Average)           (None, 1000)         0           ['dense_232[0][0]',              \n",
      "                                                                  'dense_233[0][0]']              \n",
      "                                                                                                  \n",
      " dense_234 (Dense)              (None, 1000)         1001000     ['average_20[0][0]']             \n",
      "                                                                                                  \n",
      " dense_235 (Dense)              (None, 10000)        10010000    ['dense_234[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,013,000\n",
      "Trainable params: 14,013,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MODEL 3\n",
    "\n",
    "# get input ready\n",
    "img_in_layer = Input(shape=(g_EMBIMG_SIZE,))\n",
    "bow_in_layer = Input(shape=(g_BAGOFWORDS_SIZE,))\n",
    "# send through FF\n",
    "img_in_emb_layer = Dense(EMBEDDING_SIZE, activation=\"tanh\")(img_in_layer)\n",
    "bow_in_emb_layer = Dense(EMBEDDING_SIZE, activation=\"tanh\")(bow_in_layer)\n",
    "# combine output from first FFs\n",
    "mix_layer = Average()([img_in_emb_layer, bow_in_emb_layer ])\n",
    "# FF on combined information\n",
    "linear_layer = Dense(1000, activation=\"tanh\")(mix_layer)\n",
    "out_layer = Dense(train_processed_a.shape[1], activation=softmax)(linear_layer)\n",
    "\n",
    "\n",
    "# create model\n",
    "model_3 = Model(inputs=[img_in_layer, bow_in_layer], outputs=out_layer)\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Save Models\n",
    "While training, the loss information is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3/3 [==============================] - 8s 2s/step - loss: 15.2158 - accuracy: 0.0825 - val_loss: 15.1737 - val_accuracy: 0.2215\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 5s 2s/step - loss: 15.1954 - accuracy: 0.1405 - val_loss: 15.1363 - val_accuracy: 0.2210\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 5s 1s/step - loss: 15.1550 - accuracy: 0.1405 - val_loss: 15.0666 - val_accuracy: 0.2210\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 7s 3s/step - loss: 15.0793 - accuracy: 0.1405 - val_loss: 14.9378 - val_accuracy: 0.2210\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 6s 2s/step - loss: 14.9378 - accuracy: 0.1405 - val_loss: 14.6957 - val_accuracy: 0.2210\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 6s 2s/step - loss: 14.6703 - accuracy: 0.1405 - val_loss: 14.2443 - val_accuracy: 0.2210\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 5s 2s/step - loss: 14.1865 - accuracy: 0.1405 - val_loss: 13.4603 - val_accuracy: 0.2210\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 5s 2s/step - loss: 13.3883 - accuracy: 0.1405 - val_loss: 12.3391 - val_accuracy: 0.2210\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 5s 1s/step - loss: 12.3790 - accuracy: 0.1405 - val_loss: 11.3069 - val_accuracy: 0.2210\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 5s 2s/step - loss: 11.6681 - accuracy: 0.1405 - val_loss: 11.0012 - val_accuracy: 0.2210\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 5s 2s/step - loss: 11.8130 - accuracy: 0.1405 - val_loss: 11.8174 - val_accuracy: 0.2210\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 6s 2s/step - loss: 13.1115 - accuracy: 0.1405 - val_loss: 13.3997 - val_accuracy: 0.2210\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 6s 2s/step - loss: 14.7153 - accuracy: 0.1294 - val_loss: 14.0419 - val_accuracy: 0.2115\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 10s 3s/step - loss: 15.4239 - accuracy: 0.1265 - val_loss: 14.0622 - val_accuracy: 0.2210\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 7s 2s/step - loss: 15.7917 - accuracy: 0.1405 - val_loss: 14.0847 - val_accuracy: 0.2210\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 6s 2s/step - loss: 16.0042 - accuracy: 0.1405 - val_loss: 14.1801 - val_accuracy: 0.2210\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 6s 2s/step - loss: 16.1441 - accuracy: 0.1283 - val_loss: 14.2787 - val_accuracy: 0.2115\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 9s 3s/step - loss: 16.1279 - accuracy: 0.1312 - val_loss: 14.0678 - val_accuracy: 0.2210\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 7s 2s/step - loss: 15.8672 - accuracy: 0.1405 - val_loss: 13.5617 - val_accuracy: 0.2210\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 5s 2s/step - loss: 15.5739 - accuracy: 0.1405 - val_loss: 13.1628 - val_accuracy: 0.2210\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 6s 2s/step - loss: 15.3116 - accuracy: 0.1405 - val_loss: 13.0549 - val_accuracy: 0.2210\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 5s 2s/step - loss: 15.0583 - accuracy: 0.1405 - val_loss: 12.9400 - val_accuracy: 0.2210\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 5s 2s/step - loss: 14.7998 - accuracy: 0.1405 - val_loss: 12.7718 - val_accuracy: 0.2210\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 9s 3s/step - loss: 14.5709 - accuracy: 0.1405 - val_loss: 12.5478 - val_accuracy: 0.2210\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 6s 2s/step - loss: 14.4062 - accuracy: 0.1405 - val_loss: 12.3601 - val_accuracy: 0.2210\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 6s 2s/step - loss: 14.2795 - accuracy: 0.1405 - val_loss: 12.3664 - val_accuracy: 0.2210\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 5s 2s/step - loss: 14.1553 - accuracy: 0.1405 - val_loss: 12.3619 - val_accuracy: 0.2210\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 5s 2s/step - loss: 14.0649 - accuracy: 0.1405 - val_loss: 12.3049 - val_accuracy: 0.2210\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 5s 2s/step - loss: 13.9833 - accuracy: 0.1405 - val_loss: 12.1661 - val_accuracy: 0.2210\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 5s 2s/step - loss: 13.8936 - accuracy: 0.1405 - val_loss: 12.1359 - val_accuracy: 0.2210\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 6s 2s/step - loss: 13.8085 - accuracy: 0.1405 - val_loss: 12.2150 - val_accuracy: 0.2210\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 6s 2s/step - loss: 13.7228 - accuracy: 0.1405 - val_loss: 12.1361 - val_accuracy: 0.2210\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 7s 2s/step - loss: 13.6507 - accuracy: 0.1405 - val_loss: 12.0775 - val_accuracy: 0.2210\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 16s 5s/step - loss: 13.5819 - accuracy: 0.1405 - val_loss: 11.9741 - val_accuracy: 0.2210\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 14s 4s/step - loss: 13.5015 - accuracy: 0.1405 - val_loss: 11.9561 - val_accuracy: 0.2210\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 7s 2s/step - loss: 13.4493 - accuracy: 0.1405 - val_loss: 11.9214 - val_accuracy: 0.2210\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 6s 2s/step - loss: 13.4051 - accuracy: 0.1300 - val_loss: 11.8481 - val_accuracy: 0.2210\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 7s 2s/step - loss: 13.3413 - accuracy: 0.1405 - val_loss: 11.8010 - val_accuracy: 0.2210\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 6s 2s/step - loss: 13.2899 - accuracy: 0.1405 - val_loss: 11.8023 - val_accuracy: 0.2210\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 10s 4s/step - loss: 13.2579 - accuracy: 0.1405 - val_loss: 11.7679 - val_accuracy: 0.2210\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = Adam(learning_rate=0.001, decay=1e-3 / 200)\n",
    "EPOCHS = 40\n",
    "for model in [model_1]:#, model_2, model_3]:\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    model.fit(x=[train_processed_img, train_processed_q], y=train_processed_a, \n",
    "                validation_data=([val_processed_img, val_processed_q], val_processed_a),\n",
    "                epochs=EPOCHS, batch_size=4000)\n",
    "    \n",
    "    # create plot illustrating the training history\n",
    "    plt.title(f\"Training Loss\")\n",
    "    plt.plot(model.history.history['loss'], label='training loss', color='orange')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    plt.title(f\"Validation Loss\")\n",
    "    plt.plot(model.history.history['val_loss'], label='validation loss')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obtain accuracy on the validation data\n",
    "\n",
    "Here the metric is based on the crowd agreement, per se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(prediction_list, true_raw, answer_tokenizer=a_tokenizer):\n",
    "    \"\"\"\n",
    "    This method scores the output prediction\n",
    "    against the true raw answers\n",
    "    \"\"\"\n",
    "    accuracy_array = []\n",
    "    # loop through prediction, detokenize\n",
    "    for index, pred in enumerate(prediction_list):\n",
    "        word = answer_tokenizer.index2word[np.argmax(pred)]\n",
    "        true_list = true_raw[index]\n",
    "#         print(word, true_list)\n",
    "        accuracy_array.append(np.minimum(1.0, true_list.count(word)/3.0))\n",
    "    return accuracy_array\n",
    "\n",
    "def get_predictions(prediction_list, answer_tokenizer=a_tokenizer):\n",
    "    \"\"\"\n",
    "    returns predicted words\n",
    "    \"\"\"\n",
    "    predicted_words = []\n",
    "    # loop through prediction, detokenize\n",
    "    for index, pred in enumerate(prediction_list):\n",
    "        word = answer_tokenizer.index2word[np.argmax(pred)]\n",
    "        predicted_words.append(word)\n",
    "    return predicted_words\n",
    "\n",
    "def url2truelist(data):\n",
    "    \"\"\"\n",
    "    This method obtains a list of lists portraying \n",
    "    the characterized image labels.\n",
    "    \"\"\"\n",
    "    answers = []\n",
    "    for x in data:\n",
    "        tmp = []\n",
    "        for y in x['answers']:\n",
    "            tmp.append(y['answer'])\n",
    "        answers.append(tmp)\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://ivc.ischool.utexas.edu/VizWiz_final/vqa_data/Annotations/val.json\"\n",
    "split_val_data = requests.get(data_url, allow_redirects=True)\n",
    "data = split_val_data.json()\n",
    "true_list = url2truelist(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2306666666666667\n",
      "0.42966666666666664\n",
      "0.42266666666666663\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model in [model_1, model_2, model_3]:\n",
    "    prediction_list = model.predict([np.array(val_processed_img), np.array(val_processed_q)])\n",
    "    score_array = np.average(score(prediction_list, true_list))\n",
    "    print(score_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions for first 1000 samples of testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_1 # best model\n",
    "prediction_list = model.predict([np.array(test_processed_img), np.array(test_processed_q)])\n",
    "prediction_list = get_predictions(prediction_list)\n",
    "df = pd.DataFrame(prediction_list)\n",
    "df.to_csv(\"results.csv\", header = None, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
